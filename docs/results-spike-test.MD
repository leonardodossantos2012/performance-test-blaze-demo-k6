# An√°lise de Resultados - Teste de Spike (Spike Test)

## Resumo Executivo

O teste de **Spike Test** foi executado simulando um pico s√∫bito de carga de **0 a 1000 usu√°rios virtuais (VUs)**, testando a capacidade do sistema de lidar com aumentos abruptos de tr√°fego. Os resultados indicam que o sistema apresenta **s√©rias dificuldades** em lidar com picos de carga.

### Status Geral: ‚ö†Ô∏è **CR√çTICO**

- **Total de Requisi√ß√µes**: 122,033
- **Requisi√ß√µes Falhadas**: 28,865 (24%)
- **Thresholds Violados**: 3
- **Checks Falhados**: 56,400
- **Pico de VUs**: 1,000 usu√°rios virtuais

---

## Caracter√≠sticas do Teste de Spike

### Perfil de Carga

| M√©trica | Valor |
|---------|-------|
| **VUs M√≠nimas** | 0 |
| **VUs M√°ximas** | 1,000 |
| **Padr√£o de Carga** | Spike (pico s√∫bito) |
| **Total de Itera√ß√µes** | 43,873 |
| **Itera√ß√µes Perdidas** | 28,876 (65.8% de perda) |
| **Taxa de Itera√ß√µes** | 112.49/s |

**Observa√ß√£o**: Um teste de spike simula um aumento abrupto e significativo de carga, similar a eventos como promo√ß√µes rel√¢mpago, lan√ßamentos de produtos, ou eventos virais. O sistema deve ser capaz de escalar rapidamente e manter a estabilidade.

---

## M√©tricas Principais

### Requisi√ß√µes HTTP

| M√©trica | Valor |
|---------|-------|
| Total de Requisi√ß√µes | 122,033 |
| Taxa de Requisi√ß√µes | 312.90/s |
| Requisi√ß√µes Falhadas | 28,865 (24.00%) |
| Requisi√ß√µes Bem-sucedidas | 93,168 (76.00%) |

### Performance de Resposta

| M√©trica | Valor | Status |
|---------|-------|--------|
| **Tempo M√©dio de Resposta** | 2,041.08 ms (2.04s) | üî¥ Cr√≠tico |
| **Tempo M√≠nimo** | 58.29 ms | ‚úÖ Bom |
| **Tempo Mediano (P50)** | 471.47 ms | ‚ö†Ô∏è Aceit√°vel |
| **Tempo M√°ximo** | 10,583.69 ms (10.6s) | üî¥ Cr√≠tico |
| **Percentil 90 (P90)** | 6,403.83 ms (6.4s) | üî¥ **FALHOU** |
| **Percentil 95 (P95)** | 8,395.68 ms (8.4s) | üî¥ Cr√≠tico |

**An√°lise Cr√≠tica**: 
- O P90 de **6.4 segundos** √© **quase o dobro** do observado no load test (3.4s)
- Indica que durante o pico, o sistema sofre degrada√ß√£o severa de performance
- 10% das requisi√ß√µes demoraram mais de 6 segundos, violando thresholds de performance

### Dura√ß√£o da Itera√ß√£o

| M√©trica | Valor |
|---------|-------|
| Dura√ß√£o M√©dia | 5,870.48 ms (5.9s) |
| Dura√ß√£o M√≠nima | 124.39 ms |
| Dura√ß√£o Mediana | 3,540.24 ms (3.5s) |
| Dura√ß√£o M√°xima | 38,923.13 ms (38.9s) |
| P90 | 15,362.97 ms (15.4s) |
| P95 | 18,765.19 ms (18.8s) |

**Observa√ß√£o**: As itera√ß√µes demoraram quase **o dobro** do tempo em compara√ß√£o ao load test, indicando que o sistema n√£o consegue manter a performance sob picos s√∫bitos.

---

## An√°lise de Falhas

### Taxa de Falha por Tipo

1. **http_req_failed**: 24.00% (28,865 falhas)
   - Mesma taxa de falha do load test
   - Indica que o sistema n√£o piora significativamente em termos de taxa de erro durante picos
   - Por√©m, a **severidade** dos problemas aumenta (tempos de resposta muito maiores)

2. **purchase_success**: 37.00% de sucesso (63% de falha)
   - Taxa id√™ntica ao load test
   - Apenas 16,338 compras bem-sucedidas de 43,873 tentativas
   - **27,535 transa√ß√µes perdidas** durante o pico
   - Impacto financeiro significativo em eventos de alta demanda

### Itera√ß√µes Perdidas

- **Dropped Iterations**: 28,876
- **Taxa de Perda**: 65.8% (muito alta!)
- **Compara√ß√£o com Load Test**: 35% de perda
- **An√°lise**: O sistema perde quase **o dobro** de itera√ß√µes durante picos, indicando problemas graves de capacidade

---

## An√°lise de Checks

### Resumo de Checks

| Check | Passou | Falhou | Taxa de Sucesso | Status |
|-------|--------|--------|-----------------|--------|
| homepage status is 200 | 42,543 | 1,330 | 96.97% | ‚ö†Ô∏è Aceit√°vel |
| reserve status is 200 | 17,430 | 26,443 | 39.73% | üî¥ **CR√çTICO** |
| reserve page contains flights | 17,430 | 26,443 | 39.73% | üî¥ **CR√çTICO** |
| purchase status is 200 | 16,857 | 573 | 96.71% | ‚ö†Ô∏è Aceit√°vel |
| purchase page loaded | 16,857 | 573 | 96.71% | ‚ö†Ô∏è Aceit√°vel |
| confirmation status is 200 | 16,338 | 519 | 96.92% | ‚ö†Ô∏è Aceit√°vel |
| purchase confirmed | 16,338 | 519 | 96.92% | ‚ö†Ô∏è Aceit√°vel |

### Pontos Cr√≠ticos Identificados

1. **P√°gina de Reserva (Reserve)**: 
   - Taxa de falha de **60.27%** (26,443 falhas em 43,873 tentativas)
   - **CR√çTICO**: Mesmo problema identificado no load test, mas com impacto ainda maior durante picos
   - A p√°gina n√£o consegue lidar com o aumento s√∫bito de carga
   - Poss√≠veis causas: 
     - Falta de cache adequado
     - Queries de banco de dados n√£o otimizadas
     - Aus√™ncia de rate limiting inteligente
     - Falta de auto-scaling

2. **Homepage**: 
   - 96.97% de sucesso √© aceit√°vel, mas ainda h√° 1,330 falhas
   - Durante picos, mesmo a homepage sofre degrada√ß√£o

3. **Fluxo de Compra**:
   - Taxa de sucesso alta (96%+), mas n√∫meros absolutos preocupantes
   - 519 falhas na confirma√ß√£o final representam perda de receita

---

## An√°lise de Throughput

### Requisi√ß√µes e Itera√ß√µes

- **Taxa de Requisi√ß√µes**: 312.90/s (similar ao load test: 321.36/s)
- **Taxa de Itera√ß√µes**: 112.49/s (similar ao load test: 115.81/s)
- **Total de Itera√ß√µes**: 43,873
- **Itera√ß√µes Perdidas**: 28,876 (**65.8% de perda** - CR√çTICO)

**An√°lise**: Embora a taxa de requisi√ß√µes seja similar, a **taxa de perda de itera√ß√µes √© quase o dobro**, indicando que o sistema n√£o consegue processar adequadamente durante picos.

### Transfer√™ncia de Dados

- **Dados Recebidos**: 587.84 MB (1.51 MB/s)
- **Dados Enviados**: 21.18 MB (0.05 MB/s)

---

## An√°lise de Tempos de Resposta por Componente

### Breakdown de Tempo HTTP

| Componente | Tempo M√©dio | Observa√ß√£o |
|------------|-------------|------------|
| **http_req_waiting** | 2,039.94 ms | Tempo de espera do servidor (maior componente) |
| **http_req_duration** | 2,041.08 ms | Tempo total da requisi√ß√£o |
| **http_req_receiving** | 1.11 ms | Tempo de recebimento (baixo) |
| **http_req_sending** | 0.03 ms | Tempo de envio (muito baixo) |
| **http_req_blocked** | 0.24 ms | Tempo bloqueado (aumentou vs load test) |
| **http_req_connecting** | 0.08 ms | Tempo de conex√£o (aumentou vs load test) |
| **http_req_tls_handshaking** | 0.16 ms | Handshake TLS (aumentou vs load test) |

**Conclus√£o**: 
- O problema principal continua sendo o **tempo de processamento do servidor**
- Durante picos, h√° aumento nos tempos de conex√£o e bloqueio, indicando poss√≠vel satura√ß√£o de recursos de rede/conex√£o
- O sistema n√£o consegue escalar adequadamente para lidar com o pico

---

## Compara√ß√£o: Spike Test vs Load Test

| M√©trica | Load Test | Spike Test | Diferen√ßa | An√°lise |
|---------|-----------|------------|-----------|---------|
| **Total Requisi√ß√µes** | 163,896 | 122,033 | -25.5% | Menos requisi√ß√µes devido a mais itera√ß√µes perdidas |
| **Taxa de Falha HTTP** | 24% | 24% | 0% | Taxa similar, mas severidade maior |
| **P90 http_req_duration** | 3,391ms | 6,404ms | +88.7% | **Quase o dobro!** |
| **P95 http_req_duration** | 5,185ms | 8,396ms | +61.9% | Degrada√ß√£o significativa |
| **Tempo M√©dio** | 1,048ms | 2,041ms | +94.7% | **Quase o dobro** |
| **Itera√ß√µes Perdidas** | 31,683 (35%) | 28,876 (65.8%) | +88% | Taxa de perda quase dobro |
| **Taxa purchase_success** | 37% | 37% | 0% | Mesma taxa, mas impacto maior |
| **VUs M√°ximas** | 500 | 1,000 | +100% | Spike test com o dobro de VUs |

**Conclus√£o da Compara√ß√£o**:
- O sistema **n√£o escala adequadamente** para picos de carga
- Performance degrada **significativamente** durante spikes
- Taxa de perda de itera√ß√µes **quase dobra** durante picos
- Sistema precisa de melhorias urgentes em auto-scaling e capacidade

---

## Thresholds Violados

O relat√≥rio indica que **3 thresholds foram violados**:

1. **P90 de http_req_duration** (6,403.83ms) - provavelmente threshold de 3-5 segundos
2. **Taxa de falha de requisi√ß√µes** (24%) - provavelmente threshold de < 5%
3. **Taxa de sucesso de purchase** (37%) - provavelmente threshold de > 95%

---

## An√°lise de Comportamento Durante Spike

### Fase de Crescimento (Ramp-up)

Durante o aumento s√∫bito de carga de 0 para 1,000 VUs:
- Sistema provavelmente sofreu **satura√ß√£o de recursos**
- Tempos de resposta aumentaram exponencialmente
- Taxa de falhas manteve-se est√°vel (24%), mas severidade aumentou

### Fase de Pico

No pico de 1,000 VUs:
- Sistema operou pr√≥ximo ou al√©m da capacidade m√°xima
- Degrada√ß√£o severa de performance
- Alto n√∫mero de itera√ß√µes perdidas (65.8%)

### Fase de Recupera√ß√£o

Ap√≥s o pico:
- Sistema provavelmente demorou para se recuperar
- Poss√≠veis problemas de "thundering herd"
- Recursos podem ter ficado saturados mesmo ap√≥s redu√ß√£o de carga

---

## Conclus√µes

### Problemas Identificados

1. **üî¥ CR√çTICO - Falta de Auto-scaling**:
   - Sistema n√£o escala adequadamente para picos
   - Performance degrada quase 2x durante spikes
   - Necessita de implementa√ß√£o de auto-scaling horizontal

2. **üî¥ CR√çTICO - P√°gina de Reserva**:
   - Taxa de falha de 60.27% durante picos
   - Maior gargalo do sistema
   - Requer otimiza√ß√£o urgente

3. **üî¥ CR√çTICO - Taxa de Perda de Itera√ß√µes**:
   - 65.8% de itera√ß√µes perdidas √© inaceit√°vel
   - Indica problemas graves de capacidade
   - Sistema n√£o consegue processar carga durante picos

4. **üî¥ CR√çTICO - Performance Durante Picos**:
   - P90 de 6.4 segundos √© inaceit√°vel
   - Quase o dobro do tempo em compara√ß√£o ao load test
   - Experi√™ncia do usu√°rio completamente comprometida

5. **‚ö†Ô∏è ALTO - Taxa de Sucesso de Compra**:
   - Apenas 37% de sucesso
   - 27,535 transa√ß√µes perdidas durante o pico
   - Impacto financeiro direto em eventos de alta demanda

6. **‚ö†Ô∏è ALTO - Satura√ß√£o de Recursos**:
   - Aumento nos tempos de conex√£o e bloqueio
   - Indica poss√≠vel satura√ß√£o de pool de conex√µes
   - Necessita revis√£o de configura√ß√µes de conex√£o

### Recomenda√ß√µes Espec√≠ficas para Spike Tests

1. **Imediato**:
   - Implementar **auto-scaling horizontal** (ex: Kubernetes HPA, AWS Auto Scaling)
   - Configurar **alertas proativos** para detectar picos antes que afetem usu√°rios
   - Implementar **rate limiting inteligente** com filas
   - Otimizar p√°gina de reserva (maior gargalo)

2. **Curto Prazo**:
   - Implementar **cache distribu√≠do** (Redis, Memcached)
   - Otimizar queries de banco de dados cr√≠ticas
   - Implementar **circuit breakers** para proteger o sistema
   - Adicionar **load balancers** com health checks
   - Implementar **connection pooling** adequado

3. **M√©dio Prazo**:
   - Implementar **CDN** para assets est√°ticos
   - Considerar **arquitetura de microservi√ßos** para melhor escalabilidade
   - Implementar **message queues** para processamento ass√≠ncrono
   - Revisar arquitetura para suportar picos de carga
   - Implementar **database read replicas** para distribuir carga

4. **Estrat√©gias de Mitiga√ß√£o para Picos**:
   - **Queue System**: Implementar filas para processar requisi√ß√µes durante picos
   - **Graceful Degradation**: Oferecer funcionalidades reduzidas durante picos
   - **Pre-warming**: Pr√©-aquecer recursos antes de eventos conhecidos
   - **Traffic Shaping**: Limitar taxa de requisi√ß√µes por usu√°rio/IP
   - **Caching Agressivo**: Cache de resultados de queries frequentes

5. **Testes Adicionais**:
   - Executar **teste de stress** para identificar ponto de quebra exato
   - Executar **teste de endurance** para verificar vazamentos de mem√≥ria
   - Executar **teste de volume** para validar capacidade m√°xima
   - Executar **teste de capacidade** para determinar limites reais

---

## M√©tricas de Refer√™ncia para Spike Tests

Para sistemas que precisam lidar com picos de carga, recomenda-se:
- **Tempo de resposta P90 durante picos**: < 2 segundos (atual: 6.4s)
- **Taxa de erro HTTP durante picos**: < 1% (atual: 24%)
- **Taxa de sucesso de transa√ß√µes cr√≠ticas durante picos**: > 95% (atual: 37%)
- **Taxa de perda de itera√ß√µes**: < 5% (atual: 65.8%)
- **Capacidade de auto-scaling**: Escalar em < 2 minutos

O sistema atual est√° **significativamente abaixo** desses benchmarks, especialmente durante picos de carga.

---

## Impacto de Neg√≥cio

### Perdas Estimadas Durante o Spike Test

- **Transa√ß√µes Perdidas**: 27,535
- **Taxa de Falha de Requisi√ß√µes**: 24%
- **Tempo M√©dio de Resposta**: 2.04 segundos (experi√™ncia ruim)
- **P90 de Resposta**: 6.4 segundos (experi√™ncia muito ruim)

**Cen√°rio Real**: Em um evento de alta demanda (ex: Black Friday, lan√ßamento de produto):
- Sistema n√£o conseguiria atender adequadamente
- Perda significativa de receita
- Danos √† reputa√ß√£o da marca
- Poss√≠vel perda de clientes

---

**Data da An√°lise**: Baseado no relat√≥rio HTML gerado  
**Tipo de Teste**: Spike Test  
**Cen√°rio**: 0 a 1,000 VUs (pico s√∫bito)  
**Objetivo**: Validar capacidade do sistema de lidar com aumentos abruptos de carga

---

## Visualiza√ß√£o dos Resultados

![Resultado do Spike Test](./img/load-spike-result.png)

*Dashboard do K6 Performance Test Report mostrando os resultados do teste de spike com 122,033 requisi√ß√µes totais, 28,865 requisi√ß√µes falhadas (24%), 3 thresholds violados e 56,400 checks falhados.*

